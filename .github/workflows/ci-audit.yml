name: JungleBook â€“ Build â€¢ Audit â€¢ Deploy

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]
  workflow_dispatch:
    inputs:
      promote_prod:
        description: "Promote last staging deploy to production?"
        type: boolean
        default: false

concurrency:
  group: junglebook-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: read
  checks: write
  deployments: write
  id-token: write

env:
  NODE_VERSION: "20"
  PYTHON_VERSION: "3.12"
  # Lighthouse thresholds (100 = perfect)
  LH_PERF_MIN: "90"
  LH_A11Y_MIN: "95"
  LH_BP_MIN: "95"
  LH_SEO_MIN: "90"
  # Vulnerability policy
  ALLOW_VULN_HIGH: "0"
  ALLOW_VULN_CRITICAL: "0"
  # Cloudflare
  CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
  CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}

jobs:
  discover:
    name: Discover apps
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Find apps/*
        id: set-matrix
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob
          APPS=()
          for d in apps/*; do
            [ -d "$d" ] || continue
            slug="$(basename "$d")"
            APPS+=("{\"slug\":\"$slug\"}")
          done
          if [ ${#APPS[@]} -eq 0 ]; then
            echo '{"include":[]}' > matrix.json
          else
            printf '{"include":[%s]}\n' "$(IFS=,; echo "${APPS[*]}")" > matrix.json
          fi
          echo "matrix=$(cat matrix.json)" >> "$GITHUB_OUTPUT"

  format_check:
    name: Format Check
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm

      - name: Install Prettier
        run: npm i -g prettier

      - name: Prettier (check)
        run: prettier --check "**/*.{js,jsx,ts,tsx,json,css,md}"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Black (check)
        run: pip install black && black --check .

  build_audit:
    name: Build & Audit (${{ matrix.slug }})
    runs-on: ubuntu-latest
    needs: [discover, format_check]
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    defaults:
      run:
        working-directory: apps/${{ matrix.slug }}
    steps:
      - uses: actions/checkout@v4

      - name: Ensure jq present
        shell: bash
        run: |
          if ! command -v jq >/dev/null 2>&1; then
            sudo apt-get update -y && sudo apt-get install -y jq
          fi

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: |
            apps/${{ matrix.slug }}/package-lock.json
            apps/${{ matrix.slug }}/npm-shrinkwrap.json

      - name: Install Node deps (if present)
        run: |
          if [ -f package.json ]; then npm ci; else echo "No package.json â€“ skipping"; fi

      - name: Build (Next.js)
        run: |
          if [ -f package.json ]; then npm run build || (echo "::error::Build failed" && exit 1); fi

      - name: (Optional) OpenNext build for static LHCI
        run: |
          if [ -f package.json ] && npm run | grep -q "cf:build"; then
            npm run cf:build || true
          fi

      - name: Unit tests (Jest)
        run: |
          if [ -f package.json ]; then npm test -- --ci || (echo "::error::Unit tests failed" && exit 1); fi

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: pip

      - name: Install JungleBook CLI
        working-directory: .
        run: pip install -e .

      - name: Run jb audit (writes AuditReport.md)
        working-directory: .
        run: jb audit "${{ matrix.slug }}"

      # ---------- Security Scans ----------
      - name: Python security scan (pip-audit)
        run: |
          pip install pip-audit
          mkdir -p audit
          pip-audit -f json -o audit/pip-audit.json || true

      - name: Node security scan (npm audit)
        run: |
          if [ -f package.json ]; then
            mkdir -p audit
            npm audit --json > audit/npm-audit.json || true
          fi

      # ---------- Lighthouse (enforced) ----------
      - name: Run Lighthouse CI (prefer staticDistDir)
        run: |
          mkdir -p audit/lhci
          if [ -d ".open-next/assets" ]; then
            npx lhci autorun \
              --collect.staticDistDir=.open-next/assets \
              --upload.target=filesystem \
              --upload.outputDir=./audit/lhci || true
          elif [ -f package.json ] && [ -f package-lock.json ]; then
            # Fallback: try to start prod server (may not work on all templates; best-effort)
            npx lhci autorun \
              --collect.startServerCommand="npm run start -- --port=5173" \
              --collect.startServerReadyPattern="ready|started|listening" \
              --collect.url=http://localhost:5173 \
              --upload.target=filesystem \
              --upload.outputDir=./audit/lhci || true
          else
            echo "No static assets or runnable server; skipping Lighthouse."
          fi

      - name: Parse & Enforce Lighthouse thresholds
        shell: bash
        run: |
          set -e
          LHR=$(ls -t audit/lhci/*.json 2>/dev/null | head -n1 || true)
          if [ -z "$LHR" ]; then
            echo "::warning::No Lighthouse JSON found; skipping enforcement"
            exit 0
          fi

          PERF=$(jq -r '.categories.performance.score * 100 | floor' "$LHR" || echo 0)
          A11Y=$(jq -r '.categories.accessibility.score * 100 | floor' "$LHR" || echo 0)
          BP=$(jq -r '.categories."best-practices".score * 100 | floor' "$LHR" || echo 0)
          SEO=$(jq -r '.categories.seo.score * 100 | floor' "$LHR" || echo 0)

          echo "Lighthouse: perf=$PERF, a11y=$A11Y, bp=$BP, seo=$SEO"

          FAIL=0
          [ "$PERF" -lt "${LH_PERF_MIN}" ] && echo "::error::Performance $PERF < ${LH_PERF_MIN}" && FAIL=1
          [ "$A11Y" -lt "${LH_A11Y_MIN}" ] && echo "::error::Accessibility $A11Y < ${LH_A11Y_MIN}" && FAIL=1
          [ "$BP" -lt "${LH_BP_MIN}" ] && echo "::error::Best Practices $BP < ${LH_BP_MIN}" && FAIL=1
          [ "$SEO" -lt "${LH_SEO_MIN}" ] && echo "::error::SEO $SEO < ${LH_SEO_MIN}" && FAIL=1

          if [ $FAIL -ne 0 ]; then
            exit 1
          fi

      # ---------- OPA/Rego (optional enforce) ----------
      - name: OPA conftest (governance policies)
        shell: bash
        run: |
          if [ -f audit/controls.rego ]; then
            if command -v conftest >/dev/null 2>&1; then
              conftest test audit/controls.rego
            else
              echo "::warning::conftest not installed; skipping OPA enforcement"
            fi
          else
            echo "No audit/controls.rego; skipping OPA"
          fi

      # ---------- Enforce dependency policy ----------
      - name: Enforce dependency vulnerability thresholds
        shell: bash
        run: |
          FAIL=0
          if [ -f audit/npm-audit.json ]; then
            HIGH=$(jq '.metadata.vulnerabilities.high // 0' audit/npm-audit.json)
            CRIT=$(jq '.metadata.vulnerabilities.critical // 0' audit/npm-audit.json)
            echo "npm audit: high=$HIGH critical=$CRIT"
            if [ "$CRIT" -gt "${ALLOW_VULN_CRITICAL}" ] || [ "$HIGH" -gt "${ALLOW_VULN_HIGH}" ]; then
              echo "::error::npm vulnerabilities exceed policy (high ${HIGH}, critical ${CRIT})"
              FAIL=1
            fi
          fi

          if [ -f audit/pip-audit.json ]; then
            PIPCOUNT=$(jq 'length' audit/pip-audit.json)
            echo "pip-audit findings: $PIPCOUNT"
            if [ "$PIPCOUNT" -gt 0 ]; then
              echo "::error::pip-audit found ${PIPCOUNT} issues"
              FAIL=1
            fi
          fi

          exit $FAIL

      # ---------- Upload artifacts ----------
      - name: Upload Audit Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: audit-${{ matrix.slug }}
          path: apps/${{ matrix.slug }}/audit/AuditReport.md

      - name: Upload Lighthouse results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lhci-${{ matrix.slug }}
          path: apps/${{ matrix.slug }}/audit/lhci/**
          if-no-files-found: ignore

      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-${{ matrix.slug }}
          path: |
            apps/${{ matrix.slug }}/audit/npm-audit.json
            apps/${{ matrix.slug }}/audit/pip-audit.json
          if-no-files-found: ignore

      - name: Upload build artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: build-${{ matrix.slug }}
          path: |
            apps/${{ matrix.slug }}/.open-next/**
            apps/${{ matrix.slug }}/.next/**
          if-no-files-found: ignore

  deploy_staging:
    name: Deploy Staging (${{ matrix.slug }})
    runs-on: ubuntu-latest
    needs: build_audit
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    defaults:
      run:
        working-directory: apps/${{ matrix.slug }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Wrangler
        run: npm i -g wrangler@4.40.2

      - name: Cloudflare preview deploy
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          if [ -f package.json ]; then
            npm run cf:build || true
            npm run cf:deploy
          else
            echo "No package.json â€“ skipping deploy"
          fi

      - name: D1 migrations (if schema present)
        if: hashFiles('apps/${{ matrix.slug }}/db/schema.sql') != ''
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          CF_D1_DB_NAME: ${{ secrets.CF_D1_DB_NAME }}
        run: |
          if [ -n "${CF_D1_DB_NAME:-}" ]; then
            wrangler d1 execute "$CF_D1_DB_NAME" --file=db/schema.sql || true
            if [ -f db/seed.sql ]; then wrangler d1 execute "$CF_D1_DB_NAME" --file=db/seed.sql || true; fi
          fi

      - name: Staging summary
        if: always()
        run: |
          echo "### ${{ matrix.slug }} deployed to staging âœ…" >> $GITHUB_STEP_SUMMARY

  promote_production:
    name: Promote to Production (${{ matrix.slug }})
    runs-on: ubuntu-latest
    needs: deploy_staging
    if: github.event_name == 'workflow_dispatch' && inputs.promote_prod == true
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.discover.outputs.matrix) }}
    environment:
      name: production
      url: https://yourdomain.com
    defaults:
      run:
        working-directory: apps/${{ matrix.slug }}
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Wrangler
        run: npm i -g wrangler@4.40.2

      - name: Promote canary (placeholder)
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        run: |
          echo "Implement traffic split/version promotion if needed."
          echo "âœ… Production promotion completed (placeholder)."

      - name: Production summary
        if: always()
        run: |
          echo "### ${{ matrix.slug }} promoted to production ðŸš€" >> $GITHUB_STEP_SUMMARY

